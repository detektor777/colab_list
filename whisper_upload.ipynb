{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/detektor777/colab_list/blob/main/whisper_upload.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Перейити в гугл диск и загрузить в корень диска файл\n",
        "\n",
        "https://drive.google.com/drive/"
      ],
      "metadata": {
        "id": "R7OdheAWtwnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Имя видео файла** { display-mode: \"form\" }\n",
        "file_name = input(\"Введите имя файла: \") or \"input.mp3\""
      ],
      "metadata": {
        "id": "OBseFR5gkV7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WYSV-73rslm"
      },
      "outputs": [],
      "source": [
        "#@title ##**Установить зависимости** { display-mode: \"form\" }\n",
        "!git clone https://huggingface.co/spaces/openai/whisper\n",
        "%cd whisper\n",
        "!pip install -r requirements.txt\n",
        "!pip install gradio\n",
        "!pip install pysrt\n",
        "import pysrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Подключение к гугл диску** { display-mode: \"form\" }\n",
        "from google.colab import drive\n",
        "drive.mount('/mnt/gdrive')\n"
      ],
      "metadata": {
        "id": "eZHXI6Ukkfbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Разбить файл** { display-mode: \"form\" }\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "split = \"30_second\" #@param [\"30_second\",\"auto\"]\n",
        "chunk_folder = \"/content/whisper/audio_chunks\"\n",
        "if os.path.isdir(chunk_folder):\n",
        "    shutil.rmtree(chunk_folder)\n",
        "\n",
        "if (split == \"30_second\"):\n",
        "\n",
        "  path = '/mnt/gdrive/MyDrive/'\n",
        "  full_path = os.path.join(path, file_name)\n",
        "\n",
        "  def split_audio_file(audio_file_path, chunk_length_ms=30000):\n",
        "\n",
        "      audio = AudioSegment.from_file(audio_file_path)\n",
        "      audio_chunks = make_chunks(audio, chunk_length_ms)\n",
        "\n",
        "      os.makedirs(chunk_folder, exist_ok=True)\n",
        "\n",
        "      for i, chunk in enumerate(audio_chunks):\n",
        "          chunk_name = f'{chunk_folder}/chunk_{i:04d}.wav'\n",
        "          print(chunk_name)\n",
        "          chunk.export(chunk_name, format=\"wav\")\n",
        "\n",
        "      return chunk_folder\n",
        "\n",
        "  split_audio_file(full_path)\n",
        "\n",
        "if (split == \"auto\"):\n",
        "  from librosa.util.utils import normalize\n",
        "  import os\n",
        "  import librosa\n",
        "  import numpy as np\n",
        "  import soundfile as sf\n",
        "  import shutil\n",
        "  import audioread\n",
        "\n",
        "  import scipy.io.wavfile as wav\n",
        "  import scipy.signal as signal\n",
        "  from scipy.signal import find_peaks\n",
        "  from scipy.io import wavfile\n",
        "  import moviepy.editor as mp\n",
        "  from scipy.io import loadmat\n",
        "\n",
        "\n",
        "  chunk_folder = \"/content/whisper/audio_chunks\"\n",
        "  if os.path.isdir(chunk_folder):\n",
        "      shutil.rmtree(chunk_folder)\n",
        "  os.makedirs(chunk_folder)\n",
        "  path = '/mnt/gdrive/MyDrive/'\n",
        "\n",
        "  full_path = os.path.join(path, file_name)\n",
        "\n",
        "  def convert_to_wav(input_file):\n",
        "      file_name, ext = os.path.splitext(input_file)\n",
        "      if ext == '.wav':\n",
        "          return input_file\n",
        "\n",
        "      output_file = file_name + '.wav'\n",
        "      sound = AudioSegment.from_file(input_file, format=ext[1:])\n",
        "      sound.export(output_file, format='wav')\n",
        "      return output_file\n",
        "\n",
        "  full_path = convert_to_wav(full_path)\n",
        "  print(full_path)\n",
        "  # Загрузить аудиофайл и получить данные о сигнале\n",
        "  rate, data = wavfile.read(full_path)\n",
        "\n",
        "  # Нормализовать аудио до -3 дБ\n",
        "  target_db = -3.0\n",
        "  max_val = np.iinfo(data.dtype).max\n",
        "  target_val = np.power(10.0, target_db / 20.0) * max_val\n",
        "  data = data.astype(np.float64) * target_val / np.max(np.abs(data))\n",
        "  data = data.astype(np.int16)\n",
        "\n",
        "  # Сохранить нормализованный аудиофайл\n",
        "  normalize_file = f\"/mnt/gdrive/MyDrive/normalized_{file_name}\"\n",
        "  wavfile.write(normalize_file, rate, data)\n",
        "\n",
        "  def split_chunk(input_file, output_dir, intervals_ms):\n",
        "      # Открыть аудиофайл и загрузить его содержимое и частоту дискретизации\n",
        "      audio, sr = sf.read(input_file)\n",
        "\n",
        "      # Разделить аудиофайл на отдельные части\n",
        "      for i in range(len(intervals_ms) - 1):\n",
        "          start_ms = intervals_ms[i]\n",
        "          end_ms = intervals_ms[i+1]\n",
        "\n",
        "          # Вычислить начальный и конечный индексы в сэмплах\n",
        "          start = int(start_ms / 1000 * sr)\n",
        "          end = int(end_ms / 1000 * sr)\n",
        "\n",
        "          # Записать отдельную часть аудиофайла в новый файл\n",
        "          output_file = f'{chunk_folder}/chunk_{i:04d}.wav'\n",
        "          sf.write(output_file, audio[start:end], sr)\n",
        "\n",
        "\n",
        "  def split_audio(input_file, output_dir, min_duration=1.0, max_duration=10.0, silence_threshold=0.5, min_length=5):\n",
        "      # Загрузить аудиофайл и получить данные о сигнале\n",
        "      audio_file, sr = librosa.load(input_file, sr=None, mono=True)\n",
        "\n",
        "      # Рассчитать длительность кадра и размер кадра\n",
        "      frame_duration = 0.025\n",
        "      frame_len = int(frame_duration * sr)\n",
        "\n",
        "      # Рассчитать пороговое значение сигнала энергии для определения тишины\n",
        "      peak_threshold = np.max(audio_file) * silence_threshold\n",
        "\n",
        "      # Рассчитать сигнал энергии\n",
        "      audio_file = np.concatenate((audio_file, np.zeros(frame_len - len(audio_file) % frame_len)))\n",
        "      energies = np.sum(np.square(audio_file.reshape(-1, frame_len)), axis=1)\n",
        "\n",
        "      # Найти пики в сигнале энергии\n",
        "      peak_indices, _ = find_peaks(energies, height=peak_threshold)\n",
        "\n",
        "      # Создать массив интервалов тишины\n",
        "      silence_intervals = []\n",
        "\n",
        "      # Если первый пик не в начале сигнала, добавить интервал от начала до первого пика\n",
        "      if peak_indices[0] != 0:\n",
        "          silence_intervals.append((0, peak_indices[0] * frame_len))\n",
        "\n",
        "      # Добавить интервалы тишины между пиками, если длина интервала больше чем min_duration\n",
        "      for i in range(len(peak_indices) - 1):\n",
        "          start = peak_indices[i] * frame_len\n",
        "          end = peak_indices[i+1] * frame_len\n",
        "          duration = (end - start) / sr\n",
        "          if duration > min_duration:\n",
        "              silence_intervals.append((start, end))\n",
        "\n",
        "      # Добавить последний интервал тишины, если его длина больше чем min_duration и меньше или равна max_duration\n",
        "      if peak_indices[-1] * frame_len != len(audio_file) - 1:\n",
        "          start = peak_indices[-1] * frame_len\n",
        "          end = len(audio_file) - 1\n",
        "          duration = (end - start) / sr\n",
        "          if duration > min_duration and duration <= max_duration:\n",
        "              silence_intervals.append((start, end))\n",
        "\n",
        "      silence_intervals = [(start * 1000 / sr, end * 1000 / sr) for start, end in silence_intervals]\n",
        "\n",
        "      means = []\n",
        "      for start, end in silence_intervals:\n",
        "          mean = (start + end) / 2\n",
        "          means.append(mean)\n",
        "      # вычислить длину аудиофайла в миллисекундах и добавить ее в конец списка intervals_ms\n",
        "      file_duration_ms = np.round(len(audio_file) / sr * 1000).astype(int)\n",
        "      means = np.append(means, file_duration_ms)\n",
        "      means = np.insert(means, 0, 0)\n",
        "      means = means.astype(int)\n",
        "      i = 0\n",
        "      min_interval = 15000\n",
        "      max_interval = 30000\n",
        "      while i < len(means) - 1:\n",
        "          # проверить, если следующий элемент меньше чем текущий элемент + 15\n",
        "          if means[i+1] < means[i] + min_interval:\n",
        "              # удалить следующий элемент\n",
        "              means = np.delete(means, i+1)\n",
        "          # проверить, если следующий элемент равен текущему элементу + 15 и меньше чем текущий элемент + 30\n",
        "          elif means[i+1] == means[i] + min_interval and means[i+1] < means[i] + max_interval:\n",
        "              # оставить следующий элемент и перейти к следующей итерации\n",
        "              i += 1\n",
        "          # проверить, если следующий элемент больше чем текущий элемент + 30\n",
        "          elif means[i+1] > means[i] + max_interval:\n",
        "              # добавить новый элемент, который будет равен текущему + 30 и перейти к следующей итерации\n",
        "              means = np.insert(means, i+1, means[i]+max_interval)\n",
        "              i += 1\n",
        "          else:\n",
        "              i += 1\n",
        "      means = np.append(means, file_duration_ms)\n",
        "      print(silence_intervals)\n",
        "      print(means)\n",
        "      split_chunk(full_path, chunk_folder, means)\n",
        "      return means\n",
        "\n",
        "  time_labels = split_audio(normalize_file, chunk_folder)"
      ],
      "metadata": {
        "id": "xgBqiVmgk3Mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Установка модели** { display-mode: \"form\" }\n",
        "import os\n",
        "os.system(\"pip install git+https://github.com/openai/whisper.git\")\n",
        "import gradio as gr\n",
        "import whisper\n",
        "\n",
        "from share_btn import community_icon_html, loading_icon_html, share_js\n",
        "\n",
        "model = whisper.load_model(\"large-v2\")\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "dMhWUqKdNzn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Запуск** { display-mode: \"form\" }\n",
        "import os\n",
        "\n",
        "import pysrt\n",
        "\n",
        "def create_subtitles(start_time, end_time, text):\n",
        "    subs = pysrt.SubRipFile()\n",
        "    subs.append(pysrt.SubRipItem(index=1, start=start_time, end=end_time, text=text))\n",
        "    return subs\n",
        "    \n",
        "def inference(audio):\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    \n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    \n",
        "    _, probs = model.detect_language(mel)\n",
        "    \n",
        "    options = whisper.DecodingOptions(fp16 = False)\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    \n",
        "    print(result.text)\n",
        "    return result.text, gr.update(visible=True), gr.update(visible=True), gr.update(visible=True)\n",
        "\n",
        "# Обработка каждого куска и запись результата в файл\n",
        "result_text = \"\"\n",
        "chunk_folder = \"/content/whisper/audio_chunks\"\n",
        "chunk_files = sorted(os.listdir(chunk_folder))\n",
        "for i in range(len(chunk_files)):\n",
        "    if file_name.endswith('.wav'):\n",
        "        audio_file = chunk_files[i]\n",
        "        file_path = os.path.join(chunk_folder, audio_file)\n",
        "        text = inference(file_path)[0]\n",
        "        result_text += text\n",
        "\n",
        "        start_time = time_labels[i]\n",
        "        end_time = time_labels[i+1] if i+1<len(time_labels) else start_time + 5000\n",
        "        subs = create_subtitles(start_time, end_time, text)\n",
        "        result_subs.extend(subs)\n",
        "\n",
        "# Сохранение результата в файл\n",
        "with open('result.txt', 'w') as f:\n",
        "    f.write(result_text)\n",
        "result_subs.save(\"subtitles.srt\")"
      ],
      "metadata": {
        "id": "lQuY8YCTXgtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "with open('result.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# заменяем конец предложения на перенос строки\n",
        "text = re.sub(r'([.?!])\\s+', r'\\1\\n', text)\n",
        "\n",
        "with open('result.txt', 'w') as f:\n",
        "    f.write(text)\n",
        "    \n",
        "#@title ##**Скачать результат** { display-mode: \"form\" }\n",
        "from google.colab import files\n",
        "\n",
        "# загрузка файла result.txt в Colab\n",
        "files.download('result.txt')"
      ],
      "metadata": {
        "id": "W5KkrfYpog_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}